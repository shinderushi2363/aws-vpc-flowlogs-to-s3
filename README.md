# 🛡️ AWS Project: Configure VPC Flow Logs and Store Logs in S3 Using IAM Role

## 📘 Overview

This project demonstrates how to enable **VPC Flow Logs** to capture detailed information about the IP traffic going to and from network interfaces in an AWS VPC. These logs are then delivered securely to an **Amazon S3 bucket** using a custom **IAM role with appropriate permissions**.

This setup enables **long-term storage**, **centralized logging**, and **network traffic monitoring** — which is essential for **security auditing**, **performance analysis**, and **compliance**.

---

## 🎯 Objective

- ✅ Enable VPC Flow Logs for a selected VPC.
- ✅ Store the logs in an Amazon S3 bucket.
- ✅ Use an IAM role to manage secure access between the VPC Flow Logs service and the bucket.
- ✅ Analyze and understand the log data structure.

---

## 🧰 AWS Services Used

| Service        | Purpose                                 |
|----------------|------------------------------------------|
| Amazon VPC     | Create a virtual network (VPC)           |
| Amazon S3      | Store log files generated by Flow Logs   |
| AWS IAM        | Create roles and permissions             |
| EC2 Instance   | Generate test traffic (ping, curl, etc.) |

---

## 📌 Real-World Use Case

> Imagine you run a company hosting applications inside a private network (VPC). To secure and audit your infrastructure, you want to track all **incoming** and **outgoing** network traffic. With **VPC Flow Logs**, you can now **record every interaction** in and out of your network. These logs are then sent to an **S3 bucket** where they are archived and available for analysis later.

---

## 🛠️ Step-by-Step Implementation

### 🔹 Step 1: Create a VPC
- Created a VPC (`vpc-flowlog-demo`) in the N. Virginia region.
- Subnets and default components were auto-generated.
> 🧠 *Think of this as building a secure office building.*

---

### 🔹 Step 2: Create an S3 Bucket
- Bucket Name: `vpc-flow-logs-bucket-rushikesh123`
- Disabled public access.
- Enabled versioning (optional).
- Folder structure auto-created by AWS Flow Logs:
AWSLogs/<account-id>/vpcflowlogs/<region>/<year>/<month>/<day>/

yaml
Copy
Edit
> 🧠 *Think of this as a digital locker that stores CCTV recordings.*

---

### 🔹 Step 3: Create IAM Role for VPC Flow Logs
- Trusted entity: `vpc-flow-logs.amazonaws.com`
- IAM role name: `vpc-flowlogs-to-s3-role`
- Purpose: Allow AWS to assume this role and write logs into the S3 bucket.

#### 🛡️ Trust Policy:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowVPCAccess",
      "Effect": "Allow",
      "Principal": {
        "Service": "vpc-flow-logs.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
🔹 Step 4: Create IAM Policy and Attach to Role
🛡️ IAM Permissions Policy:
json
Copy
Edit
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowS3Put",
      "Effect": "Allow",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::vpc-flow-logs-bucket-rushikesh123/*"
    }
  ]
}
Attached this policy to the IAM role.

🧠 You’re telling the “delivery guy” (Flow Logs) they can drop files into the S3 bucket.

🔹 Step 5: Configure VPC Flow Logs
Selected the created VPC.

Filter: All traffic (Accept + Reject)

Destination: Send to an Amazon S3 bucket

S3 Bucket ARN: arn:aws:s3:::vpc-flow-logs-bucket-rushikesh123

IAM Role ARN: Role created above

Log format: AWS default (GZIP compressed)

🔹 Step 6: Generate Traffic Using EC2 (Optional but Recommended)
Used an existing EC2 instance to:

ping google.com

curl http://example.com

This generates real traffic which Flow Logs will capture.

🔹 Step 7: Verify Logs in S3
Waited ~5–10 minutes.

.log.gz files appeared in the S3 path:

swift
Copy
Edit
AWSLogs/301491567872/vpcflowlogs/us-east-1/2025/06/20/
Downloaded .log.gz, uncompressed, and opened to analyze.